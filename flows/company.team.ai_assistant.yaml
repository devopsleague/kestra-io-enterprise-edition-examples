id: ai_assistant
namespace: company.team

inputs:
  - id: user_context
    type: STRING

variables:
  pre_prompt: "You're an senior product manager with a strong baground in user research."
  new_discussion_prompt: "Write a friendly message to welcome the user and ask an open question (what, when, where, etc.) to engage a new discussion"
  follow_up_prompt: "It's been quite a long time you didn't message the user. Write a follow up question to get some news"
  discovery_prompt: "The user already gave you some information about his issues or project timeline. Part of a sales discovery framework set in your sales motion, write a question to deep-dive and get more information about high level use case, project timeline, etc."

tasks:
  - id: llm_categorization
    type: io.kestra.plugin.core.http.Request
    uri: https://api-inference.huggingface.co/models/facebook/bart-large-mnli
    method: POST
    contentType: application/json
    headers:
      Authorization: "Bearer {{ secret('HF_API_TOKEN') }}"
    formData:
      inputs: "{{ inputs.user_context }}"
      parameters:
        candidate_labels:
          - "new discussion"
          - "follow up"
          - "discovery"

  - id: message_category
    type: io.kestra.plugin.core.debug.Return
    format: "{{ json(outputs.llm_categorization.body).labels[0] }}"

  - id: llm_prompting
    type: io.kestra.plugin.core.flow.Switch
    value: "{{ json(outputs.llm_categorization.body).labels[0] }}"
    cases:
      "new discussion":
        - id: new_discussion_prompt
          type: io.kestra.plugin.core.http.Request
          uri: https://api-inference.huggingface.co/models/Qwen/Qwen2.5-1.5B-Instruct/v1/chat/completions
          method: POST
          contentType: application/json
          headers:
            Authorization: "Bearer {{ secret('HF_API_TOKEN') }}"
          formData:
            model: "Qwen/Qwen2.5-1.5B-Instruct"
            messages: [
              {"role": "system", "content": "{{ vars.pre_prompt }}. {{vars.new_discussion_prompt }}"},
              {"role": "user", "content": "{{ inputs.user_context }}"}
            ]

        - id: log_response
          type: io.kestra.plugin.core.log.Log
          message: "{{ json(outputs.new_discussion_prompt.body) }}"
            
      "follow up":
        - id: follow_up_prompt
          type: io.kestra.plugin.core.http.Request
          uri: https://api-inference.huggingface.co/models/Qwen/Qwen2.5-1.5B-Instruct/v1/chat/completions
          method: POST
          contentType: application/json
          headers:
            Authorization: "Bearer {{ secret('HF_API_TOKEN') }}"
          formData:
            model: "Qwen/Qwen2.5-1.5B-Instruct"
            messages: [
              {"role": "system", "content": "{{ vars.pre_prompt }}. {{vars.follow_up_prompt }}"},
              {"role": "user", "content": "{{ inputs.user_context }}"}
            ]
            
        - id: log_response2
          type: io.kestra.plugin.core.log.Log
          message: "{{ json(outputs.follow_up_prompt.body) }}"

      "discovery":
        - id: discovery_prompt
          type: io.kestra.plugin.core.http.Request
          uri: https://api-inference.huggingface.co/models/Qwen/Qwen2.5-1.5B-Instruct/v1/chat/completions
          method: POST
          contentType: application/json
          headers:
            Authorization: "Bearer {{ secret('HF_API_TOKEN') }}"
          formData:
            model: "Qwen/Qwen2.5-1.5B-Instruct"
            messages: [
              {"role": "system", "content": "{{ vars.pre_prompt }}. {{vars.discovery_prompt }}"},
              {"role": "user", "content": "{{ inputs.user_context }}"}
            ]
        - id: log_response3
          type: io.kestra.plugin.core.log.Log
          message: "{{ json(outputs.discovery_prompt.body) }}"